{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from commonfunctions import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HoG(image):\n",
    "    # Resize the image to 130x276\n",
    "    resized_img = cv2.resize(image, (64, 128))\n",
    "    # print(resized_img.shape)\n",
    "\n",
    "    # Convert the original image to gray scale\n",
    "    resized_img_gray = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "    '''\n",
    "    # Specify the parameters for our HOG descriptor\n",
    "    win_size = (64, 128)  # You need to set a proper window size\n",
    "    block_size = (16, 16)\n",
    "    block_stride = (8, 8)\n",
    "    cell_size = (8, 8)\n",
    "    num_bins = 9\n",
    "    '''\n",
    "    win_size = (64, 128)  # Increase the window size\n",
    "    block_size = (32, 32)  # Increase the block size\n",
    "    block_stride = (16, 16)  # Increase the block stride\n",
    "    cell_size = (16, 16)  # Increase the cell size\n",
    "    num_bins = 18  # Increase the number of bins\n",
    "\n",
    "    # Set the parameters of the HOG descriptor using the variables defined above\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, num_bins)\n",
    "\n",
    "    # Compute the HOG Descriptor for the gray scale image\n",
    "    hog_descriptor = hog.compute(resized_img_gray)\n",
    "    return hog_descriptor\n",
    "\n",
    "def img_pre_processing(image):\n",
    "\n",
    "    # (1) crop background\n",
    "    #cropped_image=crop_background(image)\n",
    "\n",
    "    # (2) Apply Gaussian filtering to smooth out the image and remove any noise that may affect the accuracy of the HOG feature extractor\n",
    "    #we need to try different kernel sizes for the best!\n",
    "    gaussian_image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "    # Convert the image to floating point\n",
    "    gaussian_image_float = gaussian_image.astype(np.float32)\n",
    "\n",
    "    # Calculate the histogram\n",
    "    hist = cv2.calcHist([image], [0], None, [256], [0,256])\n",
    "\n",
    "    # Calculate the mean of the histogram\n",
    "    mean_hist = np.mean(hist)\n",
    "\n",
    "    # Convert the image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Extract the S channel\n",
    "    s_channel = hsv_image[:, :, 1]\n",
    "\n",
    "    # Calculate the average saturation\n",
    "    average_saturation = np.mean(s_channel)\n",
    "\n",
    "    # Decide the gamma value\n",
    "    if (average_saturation > 128) and (mean_hist > 128):\n",
    "        gamma = 1.2  # or any value greater than 1\n",
    "    else:\n",
    "        gamma = 0.8  # or any value less than 1\n",
    "\n",
    "    # Apply gamma correction\n",
    "    gamma_corrected_image = cv2.pow(gaussian_image_float/ 255, gamma)\n",
    "\n",
    "\n",
    "    final_image_before_HOG=gamma_corrected_image*255\n",
    "    \n",
    "    image=final_image_before_HOG.astype(np.uint8)\n",
    "\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pre trained model \n",
    "with open(\"Saudi_model.p\", \"rb\") as model_file:\n",
    "    trained_model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=io.imread(\"69.jpg\")\n",
    "image=img_pre_processing(img)\n",
    "feat=HoG(img)\n",
    "feat2=feat.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0050381  0.13947059 0.21004929 0.32206447 0.02607845 0.2972991 ]]\n",
      "500SAR\n"
     ]
    }
   ],
   "source": [
    "classes=['1SAR','5SAR','10SAR','50SAR','100SAR','500SAR']\n",
    "#make predictions\n",
    "predictions = trained_model.predict(feat2)\n",
    "per=trained_model.predict_proba(feat2)\n",
    "print(per)\n",
    "#convert predictions variable to int\n",
    "predictions = int(predictions)\n",
    "#type(predictions)\n",
    "print(classes[predictions])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
